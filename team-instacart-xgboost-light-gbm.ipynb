{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "64adf1163e6d5609488f1761d5841f644382e8f0"
   },
   "source": [
    "# Objective\n",
    "The objective of this Kernel is to predict the future behaviour (which products they will buy) based on the features that we have created in our EDA Notebooks.\n",
    "\n",
    "By the time you finish this example, you will be able to:\n",
    "\n",
    "Describe the steps of creating a predictive analytics model\n",
    "Use Python to manipulate ready features\n",
    "Use Python to create, combine, and delete data tables\n",
    "Use XGBoost to create a predictive model\n",
    "Apply the predictive model in order to make a prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "The data that Instacart opened up include orders of 200,000 Instacart users with each user having between 4 and 100 orders. Instacart indicates each order in the data as prior, train or test. Prior orders describe the past behaviour of a user while train and test orders regard the future behaviour that we need to predict. As a result, we want to predict which previously purchased products (prior orders) will be in a userâ€™s next order (train and test orders). For the train orders Instacart reveals the results (i.e. the ordered products) while for the test orders we do not have this piece of information. Moreover, the future order of each user can be either train or test meaning that each user will be either a train or a test user. The setting of the Instacart problem is described in the figure below. \n",
    "\n",
    "<img src=\"https://i.imgur.com/S0Miw3m.png\" width=\"350\">\n",
    "\n",
    "Each user has purchased various products during their prior orders. Moreover, for each user we know the order_id of their future order. The goal is to predict which of these products will be in a user's future order. This is a classification problem because we need to predict whether each pair of user and product is a reorder or not. This is indicated by the value of the reordered variable, i.e. reordered=1 or reordered=0 (see figure below). \n",
    "\n",
    "<img src=\"https://i.imgur.com/SxK2gsR.png\" width=\"350\">\n",
    "\n",
    "As a result we need to come up and calculate various predictor variables (X) that will describe the characteristics of a product and the behaviour of a user regarding one or multiple products. We will do so by analysing the prior orders of the dataset. We will then use the train users to create a predictive model and the test users to make our actual prediction. As a result we create a table as the following one and we train an algorithm based on predictor variables (X) and response variable (Y).\n",
    "\n",
    "<img src=\"https://i.imgur.com/Yb1CKAF.png\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method\n",
    "Our method includes the following steps:\n",
    "1. <b>Import the ready features from EDA notebooks and reshape data</b>: This step includes loading pkl (pickle) files into pandas DataFrames.\n",
    "2. <b>Create the test and train DataFrames</b>: In this step we create two distinct DataFrames that will be used in the creation and the use of the predictive model.\n",
    "4. <b>Create the preditive model</b>: In this step we employ XGBoost algorithm to create the predictive model through the train dataset.\n",
    "5. <b>Apply the model</b>: This step includes applying the model to predict the 'reordered' variable for the test dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4b4e46ce4ab5fd435bb50cb13eeb03536fa6ec41"
   },
   "source": [
    "# 1. Import packages and data\n",
    "We import the **time** package to calculate the execution time of our code. <br>\n",
    "We import the **gc** package to free-up reserved memory by Python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "# import the time package to calculate the execution time of the kernel\n",
    "import time\n",
    "#set on start variable the current time\n",
    "start = time.time()\n",
    "# run your code and create a new variable with the time\n",
    "end = time.time()\n",
    "#substract the start time from end time to calculate the execution time\n",
    "elapsed = end - start'''\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "import pandas as pd # dataframes\n",
    "import numpy as np # algebra & calculus\n",
    "\n",
    "import os\n",
    "# print(os.listdir(\"instacart_dataset\"))\n",
    "print(os.listdir(\"data\"))\n",
    "\n",
    "import gc #clean-up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7166d6789c663b7824960d603c2641344d6d53eb"
   },
   "source": [
    "Now we load the pickle file that contains the prd table with several features that we have created in our EDA notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uxp = pd.read_pickle('data/uxp.pkl')\n",
    "#uxp = uxp.iloc[0:150000]\n",
    "uxp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#### Remove triple quotes to trim your dataset and experiment with your data\n",
    "### COMMANDS FOR CODING TESTING - Get 10% of users \n",
    "uxp = uxp.loc[uxp.user_id.isin(uxp.user_id.drop_duplicates().sample(frac=0.01, random_state=25))] \n",
    "uxp.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "13f344a72b8508a82cec43039cf6e2ad2d297b71"
   },
   "source": [
    "In addition, we load the original .csv files from Instacart that contains the orders and the products that have ben purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "fa3ee87c7d318b8c436a4487f32861373db4768e"
   },
   "outputs": [],
   "source": [
    "orders = pd.read_csv('instacart_dataset/orders.csv' )\n",
    "order_products_train = pd.read_csv('instacart_dataset/order_products__train.csv')\n",
    "\n",
    "#products = pd.read_csv('../input/instacart-market-basket-analysis/products.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "89d8b8a2f498ab2a211f4ab9f4706b00879df3fa"
   },
   "source": [
    "We keep only the train and test orders, excluding all the prior orders (these that we used to create our features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2ccfa17e393c5c2851b81e9d627da463fca73eab"
   },
   "outputs": [],
   "source": [
    "orders_last = orders[(orders.eval_set=='train') | (orders.eval_set=='test') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d1d4c8767cee575315bc7d29076774833f1b0d2f"
   },
   "outputs": [],
   "source": [
    "uxp = uxp.merge(orders_last, on='user_id', how='left')\n",
    "uxp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3d8ad68cc4df7e2a638afb885b0629f516e376ae"
   },
   "outputs": [],
   "source": [
    "uxp_train = uxp[uxp.eval_set=='train']\n",
    "\n",
    "uxp_train = uxp_train.merge(order_products_train, on=['product_id', 'order_id'], how='left' )\n",
    "\n",
    "uxp_train = uxp_train.drop(['order_id','eval_set', 'add_to_cart_order'], axis=1)\n",
    "uxp_train = uxp_train.fillna(0)\n",
    "uxp_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fc427348f7286a4fb7c2b4fc6126304429ca4883"
   },
   "outputs": [],
   "source": [
    "uxp_test = uxp[uxp.eval_set=='test']\n",
    "uxp_test = uxp_test.drop(['eval_set', 'order_id'], axis=1)\n",
    "uxp_test = uxp_test.fillna(0)\n",
    "uxp_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "347131f72c78dfa70201b73fd5fdf30c271fb320"
   },
   "outputs": [],
   "source": [
    "del uxp\n",
    "del orders_last\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4cdb6ddaad1eadbf15816d892374f34daeab0e47"
   },
   "outputs": [],
   "source": [
    "uxp_train = uxp_train.set_index(['user_id', 'product_id'])\n",
    "\n",
    "'''#BALANCE REORDERED ROWS\n",
    "uxp_train_bal = uxp_train.copy()\n",
    "uxp_train_bal = uxp_train_bal[uxp_train_bal.reordered==0].sample(n=uxp_train_bal[uxp_train_bal.reordered==1].shape[0])\n",
    "uxp_train_bal = pd.concat([uxp_train_bal, uxp_train[uxp_train.reordered==1]])\n",
    "uxp_train_bal = uxp_train_bal.sample(frac=1)\n",
    "uxp_train = uxp_train_bal.copy()\n",
    "print(uxp_train.reordered.value_counts())\n",
    "del uxp_train_bal\n",
    "gc.collect()'''\n",
    "\n",
    "\n",
    "uxp_test = uxp_test.set_index(['user_id', 'product_id'])\n",
    "uxp_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uxp_test.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "uxp_train.loc[:, 'reordered'] = uxp_train.reordered.fillna(0)\n",
    "\n",
    "\n",
    "# subsample\n",
    "X_train, X_val, y_train, y_val = train_test_split(uxp_train.drop('reordered', axis=1), uxp_train.reordered,\n",
    "                                                    test_size=0.2, random_state=42)\n",
    "del uxp_train\n",
    "'''del uxp_train'''\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "770f166e2e840327da9ecda28a6b9b9638433347"
   },
   "outputs": [],
   "source": [
    "# import xgboost\n",
    "\n",
    "\n",
    "# d_train = xgboost.DMatrix(X_train, y_train)\n",
    "\n",
    "# param = {'max_depth':10, \n",
    "#          'eta':0.02,\n",
    "#          'colsample_bytree':0.4,\n",
    "#          'subsample':0.75,\n",
    "#          'silent':1,\n",
    "#          'nthread':27,\n",
    "#          'eval_metric':'logloss',\n",
    "#          'binary':'logistic',\n",
    "#          'tree_method':'hist'\n",
    "# }\n",
    "\n",
    "# watchlist= [(d_train, \"train\")]\n",
    "# bst = xgboost.train(params=param, dtrain=d_train, num_boost_round=1000, evals=watchlist, early_stopping_rounds=40, verbose_eval=5)\n",
    "# xgboost.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# rf = RandomForestRegressor(random_state = 42)\n",
    "# from pprint import pprint\n",
    "# # Look at parameters used by our current forest\n",
    "# print('Parameters currently in use:\\n')\n",
    "# pprint(rf.get_params())\n",
    "\n",
    "\n",
    "# Train on the training data\n",
    "bst = RandomForestClassifier(n_estimators=200, \n",
    "                                      min_samples_split=10, \n",
    "                                      min_samples_leaf=5, \n",
    "                                      n_jobs=-1, \n",
    "                                      random_state=42) \n",
    "print('light GBM training :-)')\n",
    "bst.fit(X_train, y_train)\n",
    "# opt_RF_pred = bst.predict_proba(df_test)[:, 1]\n",
    "print('light GBM trained :-)')\n",
    "del d_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "\n",
    "\n",
    "# f_to_use = ['uxp_total_bought',\n",
    "#         'one_shot_ratio_product',\n",
    "#         'times_last5',\n",
    "#         'times_last5_ratio',\n",
    "#         'Times_Bought_N',\n",
    "#         'total_orders',\n",
    "#         'first_order_number',\n",
    "#         'Order_Range_D',\n",
    "#         'Order_Ratio_user_id_X_product_id',\n",
    "#         'reorder_ratio',\n",
    "#         'mean_add_to_cart_order',\n",
    "#         'item_first_ratio',\n",
    "#         'item_N2_ratio',\n",
    "#         'item_N3_ratio',\n",
    "#         'item_N4_ratio',\n",
    "#         'item_N5_ratio',\n",
    "#         'order_size_avg',\n",
    "#         'order_number',\n",
    "#         'order_dow',\n",
    "#         'order_hour_of_day',\n",
    "#         'days_since_prior_order']\n",
    "\n",
    "# d_train = lgb.Dataset(X_train[f_to_use],\n",
    "#                       label=y_train) \n",
    "\n",
    "# params = {\n",
    "#     'task': 'train',\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'objective': 'binary',\n",
    "#     'metric': {'binary_logloss'},\n",
    "#     'num_leaves': 96,\n",
    "#     'max_depth': 10,\n",
    "#     'feature_fraction': 0.9,\n",
    "#     'bagging_fraction': 0.95,\n",
    "#     'bagging_freq': 5\n",
    "# }\n",
    "# ROUNDS = 50\n",
    "\n",
    "\n",
    "# print('light GBM train :-)')\n",
    "# bst = lgb.train(params, d_train, ROUNDS)\n",
    "# # lgb.plot_importance(bst, figsize=(9,20))\n",
    "# print('light GBM training :-)')\n",
    "# del d_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb.plot_importance(bst, figsize=(9, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1852208f70687fc3bcf32ca99d82b671fa23aeb6"
   },
   "outputs": [],
   "source": [
    "del [X_train, X_val, y_train, y_val]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2660f56ecb650ed00e6965032c51df3c9cdd09f1"
   },
   "outputs": [],
   "source": [
    "# d_test = xgboost.DMatrix(uxp_test)\n",
    "\n",
    "# uxp_test = uxp_test.reset_index()\n",
    "# uxp_test = uxp_test[['product_id', 'user_id']]\n",
    "\n",
    "# uxp_test[\"reordered\"] = bst.predict(d_test)\n",
    "\n",
    "# del bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uxp_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### build candidates list for test ###\n",
    "\n",
    "# # d_test = lgb.Dataset(uxp_test[f_to_use],                 \n",
    "# #                       categorical_feature=[]) \n",
    "\n",
    "# print('light GBM predict')\n",
    "# preds = bst.predict(uxp_test[f_to_use])\n",
    "\n",
    "# print('light GBM predicted')\n",
    "# uxp_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### build candidates list for test ###\n",
    "\n",
    "# d_test = lgb.Dataset(uxp_test[f_to_use],                 \n",
    "#                       categorical_feature=[]) \n",
    "\n",
    "print('light RandomForestClassifier predict')\n",
    "preds = bst.predict_proba(uxp_test[f_to_use])\n",
    "\n",
    "print('light RandomForestClassifier predicted')\n",
    "uxp_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uxp_test = uxp_test.reset_index()\n",
    "uxp_test = uxp_test[['product_id', 'user_id']]\n",
    "uxp_test['reordered'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "10285a1a2905a70dcead7b186a587ffed479d7f6"
   },
   "outputs": [],
   "source": [
    "orders_test = orders[orders.eval_set=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uxp_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bbdad3d283d0ba1daea9ddb92a1839e1d40c2f46"
   },
   "outputs": [],
   "source": [
    "uxp_test = uxp_test.merge(orders_test[[\"user_id\", \"order_id\"]], on='user_id', how='left').drop('user_id', axis=1)\n",
    "uxp_test.columns = ['product_id', 'reordered', 'order_id']\n",
    "uxp_test.product_id = uxp_test.product_id.astype(int)\n",
    "uxp_test.order_id = uxp_test.order_id.astype(int)\n",
    "uxp_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del orders\n",
    "del orders_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "\n",
    "class F1Optimizer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def get_expectations(P, pNone=None):\n",
    "        expectations = []\n",
    "        P = np.sort(P)[::-1]\n",
    "\n",
    "        n = np.array(P).shape[0]\n",
    "        DP_C = np.zeros((n + 2, n + 1))\n",
    "        if pNone is None:\n",
    "            pNone = (1.0 - P).prod()\n",
    "\n",
    "        DP_C[0][0] = 1.0\n",
    "        for j in range(1, n):\n",
    "            DP_C[0][j] = (1.0 - P[j - 1]) * DP_C[0, j - 1]\n",
    "\n",
    "        for i in range(1, n + 1):\n",
    "            DP_C[i, i] = DP_C[i - 1, i - 1] * P[i - 1]\n",
    "            for j in range(i + 1, n + 1):\n",
    "                DP_C[i, j] = P[j - 1] * DP_C[i - 1, j - 1] + (1.0 - P[j - 1]) * DP_C[i, j - 1]\n",
    "\n",
    "        DP_S = np.zeros((2 * n + 1,))\n",
    "        DP_SNone = np.zeros((2 * n + 1,))\n",
    "        for i in range(1, 2 * n + 1):\n",
    "            DP_S[i] = 1. / (1. * i)\n",
    "            DP_SNone[i] = 1. / (1. * i + 1)\n",
    "        for k in range(n + 1)[::-1]:\n",
    "            f1 = 0\n",
    "            f1None = 0\n",
    "            for k1 in range(n + 1):\n",
    "                f1 += 2 * k1 * DP_C[k1][k] * DP_S[k + k1]\n",
    "                f1None += 2 * k1 * DP_C[k1][k] * DP_SNone[k + k1]\n",
    "            for i in range(1, 2 * k - 1):\n",
    "                DP_S[i] = (1 - P[k - 1]) * DP_S[i] + P[k - 1] * DP_S[i + 1]\n",
    "                DP_SNone[i] = (1 - P[k - 1]) * DP_SNone[i] + P[k - 1] * DP_SNone[i + 1]\n",
    "            expectations.append([f1None + 2 * pNone / (2 + k), f1])\n",
    "\n",
    "        return np.array(expectations[::-1]).T\n",
    "\n",
    "    @staticmethod\n",
    "    def maximize_expectation(P, pNone=None):\n",
    "        expectations = F1Optimizer.get_expectations(P, pNone)\n",
    "\n",
    "        ix_max = np.unravel_index(expectations.argmax(), expectations.shape)\n",
    "        max_f1 = expectations[ix_max]\n",
    "\n",
    "        predNone = True if ix_max[0] == 0 else False\n",
    "        best_k = ix_max[1]\n",
    "\n",
    "        return best_k, predNone, max_f1\n",
    "\n",
    "    @staticmethod\n",
    "    def _F1(tp, fp, fn):\n",
    "        return 2 * tp / (2 * tp + fp + fn)\n",
    "\n",
    "    @staticmethod\n",
    "    def _Fbeta(tp, fp, fn, beta=1.0):\n",
    "        beta_squared = beta ** 2\n",
    "        return (1.0 + beta_squared) * tp / ((1.0 + beta_squared) * tp + fp + beta_squared * fn)\n",
    "\n",
    "\n",
    "def get_best_prediction(items, preds, pNone=None):\n",
    "#    print(\"Maximize F1-Expectation\")\n",
    "#    print(\"=\" * 23)\n",
    "    items_preds = sorted(list(zip(items, preds)), key=itemgetter(1), reverse=True)\n",
    "    P = [p for i,p in items_preds]\n",
    "    L = [i for i,p in items_preds]\n",
    "    \n",
    "    opt = F1Optimizer.maximize_expectation(P)\n",
    "    best_prediction = []\n",
    "    best_prediction += (L[:opt[0]])\n",
    "    if best_prediction == []:\n",
    "        best_prediction = ['None']\n",
    "            \n",
    "#    print(\"Prediction {} yields best E[F1] of {}\\n\".format(best_prediction, f1_max))\n",
    "    return ' '.join(list(map(str,best_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "#==============================================================================\n",
    "# load\n",
    "#==============================================================================\n",
    "sub_item = uxp_test.groupby(['order_id','product_id']).reordered.mean().reset_index()\n",
    "sub = sub_item.groupby('order_id').product_id.apply(list).to_frame()\n",
    "sub['yhat'] = sub_item.groupby('order_id').reordered.apply(list)\n",
    "sub.reset_index(inplace=True)\n",
    "\n",
    "del uxp_test, sub_item\n",
    "gc.collect()\n",
    "\n",
    "def multi(i):\n",
    "    if i%1000==0:\n",
    "        print('{:.3f} min'.format((time.time()-st_time)/60))\n",
    "    items = sub.loc[i,'product_id']\n",
    "    preds = sub.loc[i,'yhat']\n",
    "    ret = get_best_prediction(items, preds)\n",
    "    return ret\n",
    "\n",
    "st_time = time.time()\n",
    "pool = mp.Pool(4)\n",
    "callback = pool.map(multi, range(sub.shape[0]))\n",
    "\n",
    "sub['products'] = callback\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.reset_index(inplace=True)\n",
    "sub = sub[['order_id', 'products']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "17772d7cc8d0941d7b56181d0dee75805c515dad"
   },
   "outputs": [],
   "source": [
    "'''d = dict()\n",
    "for row in uxp_test.itertuples():\n",
    "    if row.reordered == 1:\n",
    "        try:\n",
    "            d[row.order_id] += ' ' + str(row.product_id)\n",
    "        except:\n",
    "            d[row.order_id] = str(row.product_id)\n",
    "\n",
    "for order in uxp_test.order_id:\n",
    "    if order not in d:\n",
    "        d[order] = 'None'\n",
    "        \n",
    "gc.collect()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ba5810033c2f8bc5726eae8feb82d83baa3979d3"
   },
   "outputs": [],
   "source": [
    "'''sub = pd.DataFrame.from_dict(d, orient='index')\n",
    "sub.reset_index(inplace=True)\n",
    "sub.columns = ['order_id', 'products']\n",
    "'''\n",
    "\n",
    "print(sub.shape[0])\n",
    "print(sub.shape[0]==75000)\n",
    "\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b97e3800103d111d135f9b16607dd54669486df"
   },
   "outputs": [],
   "source": [
    "print(os.listdir(\"../working/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd99b3201bee3133332c473b39542152a0d446ba"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"../working/submission.csv\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb5ee5b0c9d8aff0a387076e9704cceaa6b0c3d9"
   },
   "outputs": [],
   "source": [
    "submission.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRESHOLD = 0.22  # guess, should be tuned with crossval on a subset of train data\n",
    "\n",
    "# d = dict()\n",
    "# for row in uxp_test.itertuples():\n",
    "#     if row.reordered > TRESHOLD:\n",
    "#         try:\n",
    "#             d[row.order_id] += ' ' + str(row.product_id)\n",
    "#         except:\n",
    "#             d[row.order_id] = str(row.product_id)\n",
    "\n",
    "# for order in test_orders.order_id:\n",
    "#     if order not in d:\n",
    "#         d[order] = 'None'\n",
    "\n",
    "# sub = pd.DataFrame.from_dict(d, orient='index')\n",
    "\n",
    "# sub.reset_index(inplace=True)\n",
    "# sub.columns = ['order_id', 'products']\n",
    "# sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c94a399733410233a0c7342559e0357d02b977b8"
   },
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "elapsed = end - start\n",
    "elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 44315,
     "sourceId": 6644,
     "sourceType": "competition"
    },
    {
     "sourceId": 17360203,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 28449,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
